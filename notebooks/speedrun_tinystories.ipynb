{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Speedrun: TinyStories pretraining\n",
        "\n",
        "Minimal notebook for **timed** or **full** pretraining on TinyStories on dual T4 (e.g. Kaggle).\n",
        "Run cells in order. Cell 1 prepares data; Cell 2 runs DDP training (choose timed or by epoch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install (run once). On Kaggle: GPU T4 x 2, then run this cell.\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "if not (ROOT / \"cs336_systems\").exists() and (ROOT.parent / \"cs336_systems\").exists():\n",
        "    ROOT = ROOT.parent\n",
        "sys.path.insert(0, str(ROOT))\n",
        "import os\n",
        "os.chdir(ROOT)\n",
        "\n",
        "!pip install -q -r requirements.txt datasets transformers\n",
        "%cd cuda 2>/dev/null && !pip install -q -e . && %cd .. || true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare TinyStories: download, tokenize, save .pt (T4-safe: seq_len=256)\n",
        "from pathlib import Path\n",
        "from cs336_systems.tinystories_data import build_tinystories_pt\n",
        "\n",
        "SEQ_LEN = 256\n",
        "OUT_DIR = \"/kaggle/working\" if Path(\"/kaggle\").exists() else str(ROOT)\n",
        "data_path = Path(OUT_DIR) / \"tinystories.pt\"\n",
        "\n",
        "# Set max_samples=50000 for a quicker test; None = full dataset\n",
        "if not data_path.exists():\n",
        "    build_tinystories_pt(\n",
        "        output_path=data_path,\n",
        "        seq_len=SEQ_LEN,\n",
        "        max_samples=None,\n",
        "        vocab_size=10000,\n",
        "    )\n",
        "else:\n",
        "    print(f\"Using existing {data_path}\")\n",
        "print(f\"Data path: {data_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train: pick one.\n",
        "# Option A — Timed speedrun (e.g. 20 min on 2x T4)\n",
        "MAX_MINUTES = 20\n",
        "# Option B — Full pretraining (1 epoch over TinyStories)\n",
        "EPOCHS = 1\n",
        "USE_TIMED = True  # set False for full epoch run\n",
        "\n",
        "save_path = Path(OUT_DIR) / \"speedrun_model.pt\"\n",
        "cmd = (\n",
        "    f\"torchrun --nproc_per_node=2 train.py --ddp \"\n",
        "    f\"--config small --batch_size 4 --seq_len {SEQ_LEN} \"\n",
        "    f\"--data_path {data_path} --mixed_precision \"\n",
        "    f\"--save_path {save_path} \"\n",
        ")\n",
        "if USE_TIMED:\n",
        "    cmd += f\" --max_minutes {MAX_MINUTES}\"\n",
        "else:\n",
        "    cmd += f\" --epochs {EPOCHS}\"\n",
        "\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick generation (single GPU, load saved checkpoint)\n",
        "import torch\n",
        "from cs336_systems.model import CONFIGS, TransformerLM\n",
        "\n",
        "if save_path.exists():\n",
        "    model = TransformerLM.from_config(\"small\", use_flash=False)\n",
        "    model.load_state_dict(torch.load(save_path, map_location=\"cpu\", weights_only=True))\n",
        "    model.eval()\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = model.to(device)\n",
        "    \n",
        "    prompt = torch.randint(0, 10000, (1, 10), device=device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(50):\n",
        "            logits = model(prompt)\n",
        "            next_id = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "            prompt = torch.cat([prompt, next_id], dim=1)\n",
        "    print(\"Sample output (token ids):\", prompt[0].tolist()[:30])\n",
        "else:\n",
        "    print(\"No checkpoint found; run training cell first.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
